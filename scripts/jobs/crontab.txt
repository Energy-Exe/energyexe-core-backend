# EnergyExe Scheduled Import Jobs
#
# Install these cron jobs on your server:
#   crontab < scripts/jobs/crontab.txt
#
# Or install manually:
#   crontab -e
#   (paste contents below)

# Set shell and path
SHELL=/bin/bash
PATH=/usr/local/bin:/usr/bin:/bin

# Project directory (UPDATE THIS PATH!)
PROJECT_DIR=/Users/mohammadfaisal/Documents/energyexe/energyexe-core-backend

# ============================================================================
# ENTSOE Import - Daily at 6:00 AM
# ============================================================================
# Imports data from 3 days ago (ENTSOE publication lag)
# Sources: Denmark (DK), Belgium (BE), France (FR)
# ~1,872 records per day
0 6 * * * cd $PROJECT_DIR && poetry run python scripts/jobs/run_import_with_tracking.py entsoe-daily >> /tmp/entsoe-daily.log 2>&1

# ============================================================================
# ELEXON Import - Daily at 7:00 AM
# ============================================================================
# Imports UK generation data from 3 days ago
# ~140+ wind farms
0 7 * * * cd $PROJECT_DIR && poetry run python scripts/jobs/run_import_with_tracking.py elexon-daily >> /tmp/elexon-daily.log 2>&1

# ============================================================================
# Taipower Import - Every Hour at :05 minutes
# ============================================================================
# Fetches live snapshot from Taipower API
# ~23 Taiwan wind farms
# Run hourly to build historical dataset
5 * * * * cd $PROJECT_DIR && poetry run python scripts/jobs/run_import_with_tracking.py taipower-hourly >> /tmp/taipower-hourly.log 2>&1

# Alternative: Run once daily at noon if hourly is too frequent
# 0 12 * * * cd $PROJECT_DIR && poetry run python scripts/jobs/run_import_with_tracking.py taipower-hourly >> /tmp/taipower-daily.log 2>&1

# ============================================================================
# EIA Import - Monthly on 1st at 2:00 AM
# ============================================================================
# Imports USA monthly wind generation data from 2 months ago
# ~1,355 wind plants
0 2 1 * * cd $PROJECT_DIR && poetry run python scripts/jobs/run_import_with_tracking.py eia-monthly >> /tmp/eia-monthly.log 2>&1

# ============================================================================
# Optional: Clean up old logs monthly
# ============================================================================
# Remove logs older than 30 days
0 3 1 * * find /tmp -name "*-import*.log" -mtime +30 -delete

# ============================================================================
# NOTES
# ============================================================================
#
# Job Execution Flow:
# 1. Cron triggers run_import_with_tracking.py
# 2. Script creates record in import_job_executions table
# 3. Script executes appropriate import command
# 4. Script updates record with results
# 5. View status in UI at /import-jobs
#
# Monitoring:
# - View logs: tail -f /tmp/entsoe-daily.log
# - View status: Check /import-jobs page in admin UI
# - Check health: GET /api/v1/import-jobs/health/status
#
# Manual Execution:
# - Via UI: /import-jobs → "Create New Job" → Execute
# - Via CLI: poetry run python scripts/jobs/run_import_with_tracking.py entsoe-daily
#
# Troubleshooting:
# - If job fails: Check logs in /tmp/*.log
# - View error in UI: /import-jobs → filter by status=failed
# - Retry from UI: Click "Retry" button on failed job
#
